{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"gdhi-adj","text":"<p>This site contains the project documentation for <code>gdhi-adj</code>, a project  that flags outliers of GDHI data at LSOA levels and adjusts the outlier values.</p>"},{"location":"#table-of-contents","title":"Table Of Contents","text":"<ol> <li>API Reference</li> </ol> <p>Quickly find what you're looking for depending on your use case by looking at the different pages.</p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>The following prerequisites are required for <code>gdhi-adj</code>:</p> <ul> <li>Python 3.12 or higher</li> </ul>"},{"location":"#open-source-data","title":"Open Source Data","text":"<p>Below is a list of the open source data sources used for <code>gdhi-adj</code>:</p> <ul> <li>ONS Open Geography Portal LAU-LAD lookup.</li> </ul>"},{"location":"#contact","title":"\ud83d\udcec Contact","text":"<p>For questions, support, or feedback about <code>gdhi-adj</code>, please email RDSA.Support@ons.gov.uk.</p>"},{"location":"reference/","title":"API Reference","text":"<p>This part of the project documentation focuses on an information-oriented approach. Use it as a reference for the technical implementation of the <code>gdhi-adj</code> codebase.</p>"},{"location":"reference/#main-pipeline","title":"Main Pipeline","text":""},{"location":"reference/#gdhi_adj.pipeline","title":"<code>gdhi_adj.pipeline</code>","text":"<p>Run each module of the pipeline based on config parameters.</p>"},{"location":"reference/#gdhi_adj.pipeline.run_pipeline","title":"<code>run_pipeline(config_path)</code>","text":"<p>Run the GDHI adjustment pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to the configuration file.</p> required"},{"location":"reference/#preprocessing","title":"Preprocessing","text":""},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess","title":"<code>gdhi_adj.preprocess.calc_preprocess</code>","text":"<p>Module for calculations to preprocess data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess.calc_iqr","title":"<code>calc_iqr(df: pd.DataFrame, iqr_prefix: str, group_col: str, val_col: str, iqr_lower_quantile: float = 0.25, iqr_upper_quantile: float = 0.75, iqr_multiplier: float = 3.0) -&gt; pd.DataFrame</code>","text":"<p>Calculates the interquartile range (IQR) for each LSOA in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>iqr_prefix</code> <code>str</code> <p>Prefix for the IQR column names.</p> required <code>group_col</code> <code>str</code> <p>The column to group by for IQR calculation.</p> required <code>val_col</code> <code>str</code> <p>The column containing values to calculate IQR.</p> required <code>iqr_lower_quantile</code> <code>float</code> <p>The lower quantile for IQR calculation.</p> <code>0.25</code> <code>iqr_upper_quantile</code> <code>float</code> <p>The upper quantile for IQR calculation.</p> <code>0.75</code> <code>iqr_multiplier</code> <code>float</code> <p>The multiplier for the IQR to determine outlier bounds.</p> <code>3.0</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with additional columns for IQR, outlier</p> <code>DataFrame</code> <p>bounds and 'threshold' columns, indicating which threshold the zscore</p> <code>DataFrame</code> <p>breached.</p>"},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess.calc_lad_mean","title":"<code>calc_lad_mean(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Calculates the mean GDHI for each non outlier LSOA in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with an added 'mean_non_out_gdhi' column.</p>"},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess.calc_rate_of_change","title":"<code>calc_rate_of_change(df: pd.DataFrame, ascending: bool, sort_cols: list, group_col: str, val_col: str) -&gt; pd.DataFrame</code>","text":"<p>Calculate the rate of change going forward and backwards in time in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>ascending</code> <code>bool</code> <p>If True, calculates forward rate of change; otherwise, backward.</p> required <code>sort_cols</code> <code>list</code> <p>Columns to sort by before calculating rate of change.</p> required <code>group_col</code> <code>str</code> <p>The column to group by for rate of change calculation.</p> required <code>val_col</code> <code>str</code> <p>The column for which the rate of change is calculated.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing the rate of change values.</p>"},{"location":"reference/#gdhi_adj.preprocess.calc_preprocess.calc_zscores","title":"<code>calc_zscores(df: pd.DataFrame, score_prefix: str, group_col: str, val_col: str, zscore_upper_threshold: float = 3.0, zscore_lower_threshold: float = -3.0) -&gt; pd.DataFrame</code>","text":"<p>Calculates the z-scores for percent changes and raw data in DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>score_prefix</code> <code>str</code> <p>Prefix for the zscore column names.</p> required <code>group_col</code> <code>str</code> <p>The column to group by for z-score calculation.</p> required <code>val_col</code> <code>str</code> <p>The column values to calculate zscores.</p> required <code>zscore_upper_threshold</code> <code>float</code> <p>The upper threshold for z-score flag.</p> <code>3.0</code> <code>zscore_lower_threshold</code> <code>float</code> <p>The lower threshold for z-score flag.</p> <code>-3.0</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with an additional 'zscore' and 'threshold'</p> <code>DataFrame</code> <p>columns, indicating which threshold the zscore breached.</p>"},{"location":"reference/#gdhi_adj.preprocess.flag_preprocess","title":"<code>gdhi_adj.preprocess.flag_preprocess</code>","text":"<p>Module for flagging preprocessing data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.flag_preprocess.create_master_flag","title":"<code>create_master_flag(df: pd.DataFrame, zscore_calculation: bool, iqr_calculation: bool) -&gt; pd.DataFrame</code>","text":"<p>Creates a master flag based on z score and IQR flag columns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>zscore_calculation</code> <code>bool</code> <p>Whether z-score calculation is performed.</p> required <code>iqr_calculation</code> <code>bool</code> <p>Whether IQR calculation is performed.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with an additional 'master_flag' columns.</p>"},{"location":"reference/#gdhi_adj.preprocess.flag_preprocess.extract_start_end_years","title":"<code>extract_start_end_years(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Extracts the start and end years from the column headings. Args:     df (pd.DataFrame): The input DataFrame with years as headers. Returns:     Tuple[int, int]: A tuple containing the start and end years.</p>"},{"location":"reference/#gdhi_adj.preprocess.flag_preprocess.flag_rollback_years","title":"<code>flag_rollback_years(df: pd.DataFrame, rollback_year_start: int, rollback_year_end: int) -&gt; pd.DataFrame</code>","text":"<p>Flags years where the GDHI has rolled back from future years. Typically 2010-2014 has 2015 data copied to them as it is missing.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>rollback_year_start</code> <code>int</code> <p>The start year for rollback flagging.</p> required <code>rollback_year_end</code> <code>int</code> <p>The end year for rollback flagging.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with an additional 'rollback_flag' column.</p>"},{"location":"reference/#gdhi_adj.preprocess.join_preprocess","title":"<code>gdhi_adj.preprocess.join_preprocess</code>","text":"<p>Module for flagging preprocessing data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.join_preprocess.concat_wide_dataframes","title":"<code>concat_wide_dataframes(df_wide_outlier: pd.DataFrame, df_wide_mean: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Concatenates two wide dataframes to create a final wide DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df_wide_outlier</code> <code>DataFrame</code> <p>The DataFrame containing outlier data.</p> required <code>df_wide_mean</code> <code>DataFrame</code> <p>The DataFrame containing mean data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The concatenated DataFrame in wide format.</p>"},{"location":"reference/#gdhi_adj.preprocess.join_preprocess.constrain_to_reg_acc","title":"<code>constrain_to_reg_acc(df: pd.DataFrame, reg_acc: pd.DataFrame, transaction_name: str) -&gt; pd.DataFrame</code>","text":"<p>Calculate contrained and unconstrained values for each outlier case.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame with outliers to be constrained.</p> required <code>reg_acc</code> <code>DataFrame</code> <p>The regional accounts DataFrame.</p> required <code>transaction_code</code> <code>str</code> <p>Transaction code to filter regional accounts.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The constrained DataFrame.</p>"},{"location":"reference/#gdhi_adj.preprocess.pivot_preprocess","title":"<code>gdhi_adj.preprocess.pivot_preprocess</code>","text":"<p>Module for pivoting data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.pivot_preprocess.pivot_output_long","title":"<code>pivot_output_long(df: pd.DataFrame, uncon_gdhi: str, con_gdhi: str) -&gt; pd.DataFrame</code>","text":"<p>Pivots the output DataFrame to long format. Args:     df (pd.DataFrame): The input DataFrame in wide format.     uncon_gdhi (str): The column name for unconstrained GDHI.     con_gdhi (str): The column name for constrained GDHI.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The pivoted DataFrame in long format.</p>"},{"location":"reference/#gdhi_adj.preprocess.pivot_preprocess.pivot_wide_dataframe","title":"<code>pivot_wide_dataframe(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Pivots the DataFrame from long to wide format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame in long format.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The pivoted DataFrame in wide format.</p>"},{"location":"reference/#gdhi_adj.preprocess.pivot_preprocess.pivot_years_long_dataframe","title":"<code>pivot_years_long_dataframe(df: pd.DataFrame, new_var_col: str, new_val_col: str) -&gt; pd.DataFrame</code>","text":"<p>Pivots the DataFrame based on specified index, columns, and values.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>new_var_col</code> <code>str</code> <p>The name for the column containing old column names.</p> required <code>new_val_col</code> <code>str</code> <p>The name for the column containing values.</p> required <p>Returns: pd.DataFrame: The pivoted DataFrame.</p>"},{"location":"reference/#gdhi_adj.preprocess.run_preprocess","title":"<code>gdhi_adj.preprocess.run_preprocess</code>","text":"<p>Module for pre-processing data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.preprocess.run_preprocess.run_preprocessing","title":"<code>run_preprocessing(config: dict) -&gt; None</code>","text":"<p>Run the preprocessing steps for the GDHI adjustment project.</p> <p>This function performs the following steps: 1. Load the configuration settings. 2. Load the input data. 3. Pivot the DataFrame to long format. 4. Calculate percentage rate of change and flag rollback years. 5. Calculate z-scores and IQRs if desired as per config. 6. Create master flags. 7. Save interim data with all calculated values. 8. Calculate LAD mean GDHI. 9. Constrain outliers to regional accounts. 10. Pivot the DataFrame back to wide format. 11. Save the preprocessed data ready for PowerBI analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary containing user settings and</p> required <p>Returns:     None: The function does not return any value. It saves the processed     DataFrame to a CSV file.</p>"},{"location":"reference/#adjustment","title":"Adjustment","text":""},{"location":"reference/#gdhi_adj.adjustment.apportion_adjustment","title":"<code>gdhi_adj.adjustment.apportion_adjustment</code>","text":"<p>Module for apportioning values from adjustment in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.apportion_adjustment.apportion_adjustment","title":"<code>apportion_adjustment(df: pd.DataFrame, imputed_df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Apportion the adjustment values to all years for each LSOA.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing data to adjust.</p> required <code>imputed_df</code> <code>DataFrame</code> <p>DataFrame containing outlier imputed values.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with outlier values imputed and adjustment. values apportioned accross all years within LSOA.</p>"},{"location":"reference/#gdhi_adj.adjustment.apportion_adjustment.apportion_negative_adjustment","title":"<code>apportion_negative_adjustment(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Change negative values to 0 and apportion negative adjustment values to all LSOAs within an LAD/year group.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing data to adjust.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with negative adjustment values apportioned across all years within LSOA.</p>"},{"location":"reference/#gdhi_adj.adjustment.apportion_adjustment.apportion_rollback_years","title":"<code>apportion_rollback_years(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Continue to apportion the adjustments for years that are flagged as rollback years.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing all data including adjusted and rollback years.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with reapportioned values for rollback years.</p>"},{"location":"reference/#gdhi_adj.adjustment.apportion_adjustment.calc_non_outlier_proportions","title":"<code>calc_non_outlier_proportions(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Calculate the proportion of a non-outlier LSOA to the LAD for each year.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing all GDHI data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with LAD totals and proportions for non-outlier LSOAs calculated per year/LAD group.</p>"},{"location":"reference/#gdhi_adj.adjustment.apportion_adjustment.check_no_negative_values_col","title":"<code>check_no_negative_values_col(df: pd.DataFrame, col: str) -&gt; None</code>","text":"<p>Check that adjusted_con_gdhi has no negative values.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with adjusted_con_gdhi column.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If negative values are found.</p>"},{"location":"reference/#gdhi_adj.adjustment.calc_adjustment","title":"<code>gdhi_adj.adjustment.calc_adjustment</code>","text":"<p>Module for calculations to adjust data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.calc_adjustment.extrapolate_imputed_val","title":"<code>extrapolate_imputed_val(df: pd.DataFrame, imputed_df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Calculate the imputed value for a given LSOA code where the year that has been flagged as an outlier to adjust only has one valid safe year either side.</p> <p>The imputed value is extrapolated from the nearest safe year and the year 4 years after. This is to avoid short term fluctuations.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with full data for lookup.</p> required <code>imputed_df</code> <code>DataFrame</code> <p>DataFrame to calculate imputed value.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame containing outlier imputed values.</p>"},{"location":"reference/#gdhi_adj.adjustment.calc_adjustment.interpolate_imputed_val","title":"<code>interpolate_imputed_val(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Calculate the imputed value for a given LSOA code where the year that has been flagged as an outlier to adjust has a valid safe year either side.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with data to calculate imputed value.</p> required <p>Returns:     pd.DataFrame: DataFrame containing outlier imputed values.</p>"},{"location":"reference/#gdhi_adj.adjustment.filter_adjustment","title":"<code>gdhi_adj.adjustment.filter_adjustment</code>","text":"<p>Module for filtering adjustment data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.filter_adjustment.filter_adjust","title":"<code>filter_adjust(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Filter data to keep only LSOAs for adjustment and subset.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing LSOA data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Filtered DataFrame with only relevant columns and rows.</p>"},{"location":"reference/#gdhi_adj.adjustment.filter_adjustment.filter_component","title":"<code>filter_component(df: pd.DataFrame, sas_code_filter: str, cord_code_filter: str, credit_debit_filter: str) -&gt; pd.DataFrame</code>","text":"<p>Filter DataFrame by component codes.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Constrained DataFrame with component code data.</p> required <code>sas_code_filter</code> <code>str</code> <p>SAS code to filter by.</p> required <code>cord_code_filter</code> <code>str</code> <p>CORD code to filter by.</p> required <code>credit_debit_filter</code> <code>str</code> <p>Credit/Debit code to filter by.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Filtered DataFrame containing only rows matching the</p> <code>DataFrame</code> <p>specified component codes.</p>"},{"location":"reference/#gdhi_adj.adjustment.filter_adjustment.filter_year","title":"<code>filter_year(df: pd.DataFrame, start_year: int, end_year: int) -&gt; pd.DataFrame</code>","text":"<p>Filter DataFrame by a range of years inclusively. Args:     df (pd.DataFrame): Input DataFrame containing year data.     start_year (int): Start year for filtering (inclusive).     end_year (int): End year for filtering (inclusive). Returns:     pd.DataFrame: Filtered DataFrame containing only rows within the year     range.</p>"},{"location":"reference/#gdhi_adj.adjustment.flag_adjustment","title":"<code>gdhi_adj.adjustment.flag_adjustment</code>","text":"<p>Module for flagging data to adjust data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.flag_adjustment.identify_safe_years","title":"<code>identify_safe_years(df: pd.DataFrame, start_year: int = 1900, end_year: int = 2100) -&gt; pd.DataFrame</code>","text":"<p>Identify safe years for each LSOA where no adjustment is needed.</p> <p>For sequential years flagged for adjustment, the previous and next safe years are located at the end of the sequence of years.</p> <p>For end of range years flagged for adjustment, it will return one safe year in the range, and one outside, which will return NaN for con_gdhi</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>start_year</code> <code>int</code> <p>The starting year for the data range.</p> <code>1900</code> <code>end_year</code> <code>int</code> <p>The ending year for the data range.</p> <code>2100</code> <p>Returns:     df (pd.DataFrame): DataFrame with additional columns for safe years.     safe_years_df (pd.DataFrame): DataFrame containing only the rows         that need adjustment with non-outlier year values either side of         outlier years.</p>"},{"location":"reference/#gdhi_adj.adjustment.join_adjustment","title":"<code>gdhi_adj.adjustment.join_adjustment</code>","text":"<p>Module for joining adjustment data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.join_adjustment.join_analyst_constrained_data","title":"<code>join_analyst_constrained_data(df_constrained: pd.DataFrame, df_analyst: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Join analyst data to constrained data based on LSOA code and LAD code.</p> <p>Parameters:</p> Name Type Description Default <code>df_constrained</code> <code>DataFrame</code> <p>DataFrame containing constrained data.</p> required <code>df_analyst</code> <code>DataFrame</code> <p>DataFrame containing analyst data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Joined DataFrame with relevant columns.</p>"},{"location":"reference/#gdhi_adj.adjustment.join_adjustment.join_analyst_unconstrained_data","title":"<code>join_analyst_unconstrained_data(df_unconstrained: pd.DataFrame, df_analyst: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Join analyst data to unconstrained data based on LSOA code and LAD code.</p> <p>Parameters:</p> Name Type Description Default <code>df_unconstrained</code> <code>DataFrame</code> <p>DataFrame with unconstrained data.</p> required <code>df_analyst</code> <code>DataFrame</code> <p>DataFrame containing analyst data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Joined DataFrame with relevant columns.</p>"},{"location":"reference/#gdhi_adj.adjustment.pivot_adjustment","title":"<code>gdhi_adj.adjustment.pivot_adjustment</code>","text":"<p>Module for pivoting adjustment data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.pivot_adjustment.pivot_adjustment_long","title":"<code>pivot_adjustment_long(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Un-pivot (melt) the adjustment DataFrame from wide to long format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing data to be adjusted.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Pivoted DataFrame in long format.</p>"},{"location":"reference/#gdhi_adj.adjustment.pivot_adjustment.pivot_wide_final_dataframe","title":"<code>pivot_wide_final_dataframe(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Pivots the DataFrame from long to wide format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame in long format.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The pivoted DataFrame in wide format.</p>"},{"location":"reference/#gdhi_adj.adjustment.reformat_adjustment","title":"<code>gdhi_adj.adjustment.reformat_adjustment</code>","text":"<p>Module for joining adjustment data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.reformat_adjustment.reformat_adjust_col","title":"<code>reformat_adjust_col(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Reformat data within the adjust column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to be reformatted.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with reformatted columns.</p>"},{"location":"reference/#gdhi_adj.adjustment.reformat_adjustment.reformat_year_col","title":"<code>reformat_year_col(df: pd.DataFrame, start_year: int, end_year: int) -&gt; pd.DataFrame</code>","text":"<p>Reformat data within the year column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to be reformatted.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with reformatted columns.</p>"},{"location":"reference/#gdhi_adj.adjustment.run_adjustment","title":"<code>gdhi_adj.adjustment.run_adjustment</code>","text":"<p>Module for adjusting data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.run_adjustment.run_adjustment","title":"<code>run_adjustment(config: dict) -&gt; None</code>","text":"<p>Run the adjustment steps for the GDHI adjustment project.</p> <p>This function performs the following steps: 1. Load the configuration settings. 2. Load the input data. 3. Reformat adjust and year columns. 4. Filter of data for adjustment. 5. Join analyst output with constrained and unconstrained data. 6. Pivot the DataFrame to long format for manipulation. 7. Filter data by the specified year range. 8. Calculate the imputed gdhi values for outlier years. 9. Calculate adjustment values based on imputed gdhi. 10. Apportion adjustment values to all years. 11. Save interim data with all calculated values. 12. Pivot data to wide format for PowerBI QA reiteration. 13. Pivot final DataFrame to wide format for exporting. 14. Save the final adjusted data.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary containing user settings and</p> required <p>Returns:     None: The function does not return any value. It saves the processed     DataFrame to a CSV file.</p>"},{"location":"reference/#gdhi_adj.adjustment.validation_adjustment","title":"<code>gdhi_adj.adjustment.validation_adjustment</code>","text":"<p>Module for adjustment data validation in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.adjustment.validation_adjustment.check_adjust_year_not_empty","title":"<code>check_adjust_year_not_empty(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Check that for LSOAs marked for adjustment, the year column is not empty.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to be checked.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame, unchanged. This allows the function to be used in method chaining (e.g., .pipe()).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an LSOA marked for adjustment does not have a year specified to adjust.</p>"},{"location":"reference/#gdhi_adj.adjustment.validation_adjustment.check_lsoas_flagged","title":"<code>check_lsoas_flagged(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Check that not all LSOAs within an LAD are flagged for adjustment.</p> <p>This is so that there are some non-outlier LSOAs to calculate non-outlier proportions of the total GDHI within an LAD.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to be checked.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame, unchanged. This allows the function to be used in method chaining (e.g., .pipe()).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If every 'lsoa_code' within an lad_code is marked for adjustment.</p>"},{"location":"reference/#gdhi_adj.adjustment.validation_adjustment.check_years_flagged","title":"<code>check_years_flagged(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Check that not all years within an LSOA are flagged for adjustment.</p> <p>This is so that there are some non-outlier LSOAs to interpolate/extrapolate from.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to be checked.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame, unchanged. This allows the function to be used in method chaining (e.g., .pipe()).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If every year within an 'lsoa_code' is marked for adjustment.</p>"},{"location":"reference/#cord-preparation","title":"CORD Preparation","text":""},{"location":"reference/#gdhi_adj.cord_preparation.mapping_cord_prep","title":"<code>gdhi_adj.cord_preparation.mapping_cord_prep</code>","text":"<p>Module for local authority units mapped to LADs.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.mapping_cord_prep.aggregate_lad","title":"<code>aggregate_lad(df)</code>","text":"<p>Aggregate values on LADs and other identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing adjusted data with LAD codes joined.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame containing value columns now aggregated by sum on identifier columns.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.mapping_cord_prep.clean_validate_mapper","title":"<code>clean_validate_mapper(mapper_df)</code>","text":"<p>Subset the mapper and get a unique DataFrame of values.</p> <p>Parameters:</p> Name Type Description Default <code>mapper_df</code> <code>DataFrame</code> <p>DataFrame containing data used to join</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame with unique values for LADs and LAUs.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.mapping_cord_prep.join_mapper","title":"<code>join_mapper(df, mapper_df)</code>","text":"<p>Join mapper containing a lookup of LAU and LAD values, to adjusted data.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing adjusted data.</p> required <code>mapper_df</code> <code>DataFrame</code> <p>DataFrame containing LAU to LAD lookup.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame with LADs joined on LAU codes.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.mapping_cord_prep.map_S30_to_S12","title":"<code>map_S30_to_S12(config: dict, df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Run the mapping steps for the GDHI adjustment pipeline.</p> <p>This function performs the follwing steps: 1. Rename column containing S30 values to LAU and verify mapping is     required. If mapping is required: 2. Load in and clean mapper containing LAU to LAD lookup. 3. Join LAU-LAD mapper to adjusted data. 4. Aggregate to LAD if specified in config. 5. Reformat output.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.mapping_cord_prep.reformat","title":"<code>reformat(df, original_columns)</code>","text":"<p>Rename LAD columns for end format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing adjusted data and LAD codes.</p> required <code>original_columns</code> <code>list</code> <p>List of columns from original DataFrame.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: Renamed DataFrame with desired columns.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.mapping_cord_prep.rename_s30_to_lau","title":"<code>rename_s30_to_lau(config, df)</code>","text":"<p>Rename column containing S30 area codes to lau_</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary containing user settings and pipeline settings.</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame containing adjusted data.</p> required <p>Returns:</p> Name Type Description <p>pd.DataFrame: DataFrame with area code column renamed if S30 codes have been found, otherwise returns original DataFrame.</p> <code>need_mapping</code> <code>Boolean</code> <p>Returned boolean to show mapping is needed.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.transform_cord_prep","title":"<code>gdhi_adj.cord_preparation.transform_cord_prep</code>","text":"<p>Module for imputing values ready for CORD in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.transform_cord_prep.append_all_sub_components","title":"<code>append_all_sub_components(config: dict) -&gt; pd.DataFrame</code>","text":"<p>Append all DataFrames that contain separatesub-components together so that each LSOA has all sub-components present in one DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Pipeline configuration dictionary containing filepaths for the location of sub-component data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with each LSOA having many sub-components component appended.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.transform_cord_prep.impute_suppression_x","title":"<code>impute_suppression_x(df: pd.DataFrame, target_cols: List[str], transaction_col: str = 'transaction', lsoa_col: str = 'lsoa_code', transaction_value: str = 'D623', lsoa_val: List[str] = ['95', 'S']) -&gt; pd.DataFrame</code>","text":"<p>Set cells in target_cols to \"X\" where both conditions are met:   - The value in transaction_col equals transaction_value.   - The value in lsoa_col starts with any values in lsoa_val list.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input DataFrame</p> required <code>target_cols</code> <code>List[str]</code> <p>list of column names to modify.</p> required <code>transaction_col</code> <code>str</code> <p>name of the transaction column.</p> <code>'transaction'</code> <code>lsoa_col</code> <code>str</code> <p>name of the LSOA column.</p> <code>'lsoa_code'</code> <code>transaction_value</code> <code>str</code> <p>transaction value to match.</p> <code>'D623'</code> <code>lsoa_val</code> <code>List[str]</code> <p>list of starting strings for LSOA codes to match ( case sensitive).</p> <code>['95', 'S']</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with suppressed values.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.validation_cord_prep","title":"<code>gdhi_adj.cord_preparation.validation_cord_prep</code>","text":"<p>Module for validation checks prior to CORD in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.validation_cord_prep.check_lsoa_consistency","title":"<code>check_lsoa_consistency(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Performs an internal consistency check on the DataFrame to ensure 'lsoa_code' uniqueness matches the total row count.</p> <p>This function verifies that the number of unique values in the 'lsoa_code' column is exactly equal to the number of rows in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input pandas DataFrame containing an 'lsoa_code' column.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame, unchanged. This allows the function to be used in method chaining (e.g., .pipe()).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of unique 'lsoa_code' values does not match the total number of rows in the DataFrame.</p> <code>KeyError</code> <p>If the 'lsoa_code' column is missing from the DataFrame.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.validation_cord_prep.check_lsoa_count","title":"<code>check_lsoa_count(df: pd.DataFrame, df_unconstrained: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Perform a validation check to ensure that the unique lsoa_codes in the constrained DataFrame matches that in the unconstrained DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input pandas DataFrame containing an 'lsoa_code' column.</p> required <code>df_unconstrained</code> <code>DataFrame</code> <p>The unconstrained DataFrame to compare against.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame, unchanged. This allows the function to be used in method chaining (e.g., .pipe()).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of unique 'lsoa_code' values in the constrained DataFrame does not match the number of unique 'lsoa_code' values in the unconstrained DataFrame.</p> <code>KeyError</code> <p>If the 'lsoa_code' column is missing from the DataFrame.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.validation_cord_prep.check_no_negative_values_df","title":"<code>check_no_negative_values_df(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Checks all numeric columns in the DataFrame to ensure no values are less than 0.</p> <p>This function isolates numeric columns (integers and floats) and verifies that all values are non-negative. It ignores non-numeric columns (e.g., strings).</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame to be validated.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame, unchanged, for method chaining.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any negative values are found in numeric columns.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.validation_cord_prep.check_no_nulls","title":"<code>check_no_nulls(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Checks the entire DataFrame to ensure it contains no Null, NaN, or None values.</p> <p>This function scans all cells in the DataFrame. It detects standard numpy NaNs, Python None objects, and pandas pd.NA values.</p> <p>If any such value is found, it raises a ValueError.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame to be validated.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame, unchanged, for method chaining.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any null/NaN/None values are found in the DataFrame.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.validation_cord_prep.check_subcomponent_lookup","title":"<code>check_subcomponent_lookup(df: pd.DataFrame, lookup_df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>This function verifies that each unique value combination in the 'transaction' and 'account_entry' columns from the subcomponent lookup are present in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input pandas DataFrame containing subcomponent data.</p> required <code>lookup_df</code> <code>DataFrame</code> <p>The lookup DataFrame containing all combinations of subcomponents that should be present.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame, unchanged. This allows the function to be used in method chaining (e.g., .pipe()).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If all combinations of 'transaction' and 'account_entry' values from the lookup are not present in the DataFrame.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.validation_cord_prep.check_year_column_completeness","title":"<code>check_year_column_completeness(df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Verifies that the DataFrame contains a complete set of consecutive year columns.</p> <p>This function automatically identifies numeric column names (integers or strings representing integers), determines the minimum and maximum years, and checks if every year between that minimum and maximum exists as a column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The original DataFrame, unchanged, for method chaining.</p> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li>If no numeric/year columns are found.</li> <li>If there are gaps in the sequence of years detected.</li> </ul>"},{"location":"reference/#gdhi_adj.cord_preparation.run_cord_prep","title":"<code>gdhi_adj.cord_preparation.run_cord_prep</code>","text":"<p>Module for pre-processing data in the gdhi_adj project.</p>"},{"location":"reference/#gdhi_adj.cord_preparation.run_cord_prep.run_cord_preparation","title":"<code>run_cord_preparation(config: dict) -&gt; None</code>","text":"<p>Run the CORD preparation steps for the GDHI adjustment project.</p> <p>This function performs the following steps: 1. Load the configuration settings. 2. Load the input data and append all subcomponents together. 3. Map LAU S30 codes to LAD S12 codes. 4. Perform validation checks on the input data. 5. Apply CORD-specific transformations. 6. Save the prepared CORD data for further processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary containing user settings and</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>The function does not return any value. It saves the processed</p> <code>None</code> <p>DataFrame to a CSV file.</p>"},{"location":"reference/#utilities","title":"Utilities","text":""},{"location":"reference/#gdhi_adj.utils.helpers","title":"<code>gdhi_adj.utils.helpers</code>","text":"<p>Define helper functions that wrap regularly-used functions.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.convert_column_types","title":"<code>convert_column_types(df: pd.DataFrame, schema: dict, logger: logging.Logger) -&gt; pd.DataFrame</code>","text":"<p>Convert DataFrame columns data types as specified in the schema.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to convert column types.</p> required <code>schema</code> <code>dict</code> <p>The schema containing column names and their expected</p> required <code>logger</code> <code>Logger</code> <p>Logger for logging conversion actions.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with converted column types.</p> <p>Raises:</p> Type Description <code>warning</code> <p>If a column's type conversion fails.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.load_schema_from_toml","title":"<code>load_schema_from_toml(schema_path: str) -&gt; dict</code>","text":"<p>Load a schema from a TOML file.</p> <p>Parameters:</p> Name Type Description Default <code>schema_path</code> <code>str</code> <p>Path to the TOML schema file.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the schema.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.load_toml_config","title":"<code>load_toml_config(path: Union[str, pathlib.Path]) -&gt; dict | None</code>","text":"<p>Load a .toml file from a path, with logging and safe error handling.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>The path to load the .toml file from.</p> required <p>Returns:</p> Type Description <code>dict | None</code> <p>dict | None: The loaded toml file as a dictionary, or None on error.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.read_with_schema","title":"<code>read_with_schema(input_file_path: str, input_schema_path: str) -&gt; pd.DataFrame</code>","text":"<p>Reads in a csv file and compares it to a data dictionary schema.</p> <p>Parameters:</p> Name Type Description Default <code>input_file_path</code> <code>string</code> <p>Filepath to the csv file to be read in.</p> required <code>input_schema_path</code> <code>string</code> <p>Filepath to the schema file in TOML format.</p> required <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>Formatted dataFrame containing data from the csv</p> <code>DataFrame</code> <p>file.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.rename_columns","title":"<code>rename_columns(df: pd.DataFrame, schema: dict, logger: logging.Logger) -&gt; pd.DataFrame</code>","text":"<p>Rename columns in the DataFrame based on the schema. Schema should be a dict where keys are new column names and values are dicts with 'old_name'.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to rename columns in.</p> required <code>schema</code> <code>dict</code> <p>The schema containing old and new column names.</p> required <code>logger</code> <code>Logger</code> <p>Logger for logging renaming actions.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The DataFrame with renamed columns.</p>"},{"location":"reference/#gdhi_adj.utils.helpers.validate_schema","title":"<code>validate_schema(df: pd.DataFrame, schema: dict)</code>","text":"<p>Validate the DataFrame against the schema.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to validate.</p> required <code>schema</code> <code>dict</code> <p>The schema sourced from a TOML file to validate against.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If a required column fromt he scheda is missing in the</p> <code>TypeError</code> <p>If a column's type does not match the expected type in the</p>"},{"location":"reference/#gdhi_adj.utils.helpers.write_with_schema","title":"<code>write_with_schema(df: pd.DataFrame, output_schema_path: str, output_dir: str, new_filename=None)</code>","text":"<p>Writes a DataFrame to a CSV file, renaming columns and validating against a schema.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The final output DataFrame to write to CSV.</p> required <code>output_schema_path</code> <code>str</code> <p>Path to the output schema file in TOML</p> required <code>output_dir</code> <code>str</code> <p>Directory where the CSV file will be saved.</p> required <code>new_filename</code> <code>str</code> <p>New filename for the output CSV. If None,                           uses the original name.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the DataFrame does not match the schema.</p> <p>Returns:</p> Name Type Description <code>None</code> <p>Writes the DataFrame to a CSV file after validating against the</p> <p>schema.</p>"},{"location":"reference/#gdhi_adj.utils.logger","title":"<code>gdhi_adj.utils.logger</code>","text":""},{"location":"reference/#gdhi_adj.utils.logger.CustomFormatter","title":"<code>CustomFormatter</code>","text":"<p>               Bases: <code>Formatter</code></p> <p>Define logging formatter with colors for different log levels.</p>"},{"location":"reference/#gdhi_adj.utils.logger.CustomFormatter.format","title":"<code>format(record)</code>","text":"<p>Set color formatting for logger.</p>"},{"location":"reference/#gdhi_adj.utils.logger.GDHI_adj_logger","title":"<code>GDHI_adj_logger(name)</code>","text":"<p>Custom logging class for use throughout the GDHI_adj pipeline.</p>"},{"location":"reference/#gdhi_adj.utils.logger.GDHI_adj_logger--parameters","title":"Parameters","text":"<p>name : str     The name of the file the logger is being created from.</p> <p>Initialise the logger class.</p>"},{"location":"reference/#gdhi_adj.utils.transform_helpers","title":"<code>gdhi_adj.utils.transform_helpers</code>","text":"<p>Define helper functions that wrap regularly-used functions.</p>"},{"location":"reference/#gdhi_adj.utils.transform_helpers.ensure_list","title":"<code>ensure_list(x: any) -&gt; list</code>","text":"<p>Ensure the input is returned as a list.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>any</code> <p>Input value to be converted to a list.</p> required <p>Returns:     list: The input value wrapped in a list if it was not already a list.</p>"},{"location":"reference/#gdhi_adj.utils.transform_helpers.increment_until_not_in","title":"<code>increment_until_not_in(year: int, adjust_years: list, limit_year: int, is_increasing: bool = True)</code>","text":"<p>Increase or decrease year until it is not in a list of adjust_years. Args:     year (int): The starting year.     adjust_years (list): List of years to avoid.     limit_year (int): The limit year to stop at.     is_increasing (bool): If True, increase year; if False, decrease year. Returns:     int: The first year not in adjust_years list.</p>"},{"location":"reference/#gdhi_adj.utils.transform_helpers.sum_match_check","title":"<code>sum_match_check(df: pd.DataFrame, grouping_cols: list, unadjusted_col: str, adjusted_col: str, sum_tolerance: float = 1e-06)</code>","text":"<p>Check that the sums of adjusted column, matches that of the unadjusted column for the same groupings.</p> <p>If the difference exceeds a specified tolerance, raise an error.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing data for sums.</p> required <code>grouping_cols</code> <code>list</code> <p>(list): List of columns to group for sums.</p> required <code>unadjusted_col</code> <code>str</code> <p>Unadjusted column.</p> required <code>adjusted_col</code> <code>str</code> <p>Adjsuted column</p> required <code>sum_tolerance</code> <code>float</code> <p>Tolerance for the sums to match, default is</p> <code>1e-06</code> <code>based on the floating point error</code> <p>0.000001.</p> required <p>Returns:</p> Name Type Description <code>ValueError</code> <p>if adjusted and unadjusted sums do not match.</p>"},{"location":"reference/#gdhi_adj.utils.transform_helpers.to_int_list","title":"<code>to_int_list(cell: Any) -&gt; List[int]</code>","text":"<p>Convert a cell to a list of ints. Accepts:   - a comma-separated string like \"2010,2011, 2012\"   - a list/tuple of strings or numbers   - NaN/None -&gt; returns [] Raises ValueError if an item cannot be converted to int.</p>"}]}